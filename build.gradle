apply plugin: 'idea'
apply plugin: 'java'

repositories {
  flatDir dirs: "${rootDir}/lib"
  mavenCentral()
}

def hadoopVersions = [
    'old': '1.2.1',
    'new': '2.1.0-beta'
]

dependencies {
  compile 'xstream:xstream:1.2.2'
  compile 'org.apache.commons:commons-lang3:3.1'
  compile 'com.google.guava:guava:14.0.1'
  compile 'com.google.inject:guice:3.0'

  if (newHadoop) {
    compile "org.apache.hadoop:hadoop-common:${hadoopVersions.new}"
    compile "org.apache.hadoop:hadoop-hdfs:${hadoopVersions.new}"
    compile "org.apache.hadoop:hadoop-minicluster:${hadoopVersions.new}"
  } else {
    compile "org.apache.hadoop:hadoop-core:${hadoopVersions.old}"
    compile "org.apache.hadoop:hadoop-test:${hadoopVersions.old}"
  }

  compile 'org.mockito:mockito-all:1.9.5'
  compile 'org.easytesting:fest-assert:1.4'
  compile 'junit:junit:4.11'

}

boolean isNewHadoop() {
  return System.properties['newHadoop'] == 'true'
}

compileJava {
  sourceCompatibility = 1.6
  targetCompatibility = 1.6
}

task runInMemory(type: Test, dependsOn: jar) {
  testClassesDir = sourceSets.main.output.classesDir
}

task runOnHadoop(type: Exec, dependsOn: jar) {
  def allJars = []
  for (file in configurations.compile) {
    allJars.add(file)
  }
  workingDir "${rootDir}/fabric"
  def deploy_args = [files(jar.archivePath).singleFile, allJars.join(';')]
  def run_args = deploy_args + ['pl.rtshadow.lem.benchmarks.RealHdfsRunner']
  if(System.properties['arguments']) {
    run_args.add(System.properties['arguments'])
  }
  commandLine fabric_command_for(System.properties['hosts']) + ["deploy:${deploy_args.join(',')}", "run_jar_silently:${run_args.join(',')}", 'collect_results']
}

def fabric_command_for(String hosts) {
  ['fab', '--abort-on-prompts','-P',"-H ${hosts}"]
}



